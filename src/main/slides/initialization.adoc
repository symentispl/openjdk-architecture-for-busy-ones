== JVM initialization


=== safepoint 

[source,cpp]
----
SafepointMechanism::default_initialize()
----

=== !

 Roll all threads forward to a safepoint and suspend them all

[source, cpp]
----
 void SafepointSynchronize::begin() 
----

=== !

.Safe point events 

* Deoptimization
* PrintThreads
* PrintJNI
* FindDeadlock
* ThreadDump
* EnableBiasLocking
* RevokeBias
* HeapDumper
* GetAllStackTrace

=== !

.But also

* NIO Mapped Byte Buffers 
* Counted loops
* Array copying 
* JNI Critical Regions 
* JNI Handle Allocations
* Large object initialization 

=== !

.Code phase and Safepoint
* Running interpreted
When executing branching/returning byte codes interpreter
checks if the poll is armed, if so blocks in SS::block().

*  Running in native code
When returning from the native code, a Java thread must check
the safepoint _state to see if we must block.  If the
VM thread sees a Java thread in native, it does
not wait for this thread to block.  The order of the memory
writes and reads of both the safepoint state and the Java
threads state is critical.  In order to guarantee that the
memory writes are serialized with respect to each other,
the VM thread issues a memory barrier instruction.

*  Running compiled Code
Compiled code reads the local polling page that
is set to fault if we are trying to get to a safepoint.

*  Blocked
A thread which is blocked will not be allowed to return from the
block condition until the safepoint operation is complete.

*  In VM or Transitioning between states
If a Java thread is currently running in the VM or transitioning
between states, the safepointing code will poll the thread state
until the thread blocks itself when it attempts transitions to a
new state or locking a safepoint checked monitor.

// during creating vm 
// SafepointMechanism::default_initialize
// process
// The call to on_safepoint fixes the thread's oops and the first few frames.
//
// The call has been carefully placed here to cater to a few situations:
// 1) After we exit from block after a global poll
// 2) After a thread races with the disarming of the global poll and transitions from native/blocked
// 3) Before the handshake code is run
//A compiler barrier, forcing the C++ compiler to invalidate all memory assumptions
// void SafepointMechanism::process(JavaThread *thread, bool allow_suspend) 

// Wait for another thread to perform object reallocation and relocking on behalf of
// this thread.
// Raw thread state transition to _thread_blocked and back again to the original
// state before returning are performed. The current thread is required to
// change to _thread_blocked in order to be seen to be safepoint/handshake safe
// whilst suspended and only after becoming handshake safe, the other thread can
// complete the handshake used to synchronize with this thread and then perform
// the reallocation and relocking. We cannot use the thread state transition
// helpers because we arrive here in various states and also because the helpers
// indirectly call this method.  After leaving _thread_blocked we have to check
// for safepoint/handshake, except if _thread_in_native. The thread is safe
// without blocking then. Allowed states are enumerated in
// SafepointSynchronize::block(). See also EscapeBarrier::sync_and_suspend_*()
// ParallelSPCleanupThreadClosure

=== stack processing

During safepoint each thread stack is processing 

=== !

Always process three frames when starting an iteration.

.The three frames corresponds to:
* The callee frame
* The caller frame
* An extra frame to deal with unwinding safepointing on the way out. Sometimes, we also call into the runtime to on_unwind(), but then  hit a safepoint poll on the way out from the runtime.

`This allows a callee to always be able to read state from its caller without needing any special barriers.`

=== JEP-376

Concurrent Thread-Stack Processing

=== !

Remove thread-stack processing from ZGC safepoints.

It also available in Shenandoah 

Each stack processes concurrently 

Only GC uses the OopMapCache during thread stack root scanning + 
any other uses generate an oopmap but do not save it in the cache.

=== Make stack processing lazy, cooperative, concurrent, and incremental.

=== Remove all other per-thread root processing from ZGC safepoints.

=== Provide a mechanism by which other HotSpot subsystems can lazily process stacks.

=== Stack watermark
 
All GC operations that scale with the size of the heap and the size of metaspace out of safepoint operations
and into concurrent phases.

`per-thread processing`


//  GC safepoint will logically invalidate Java thread stacks by flipping a global variable.
//The stack watermark makes it possible to distinguish whether a given frame is above the watermark (assuming that stacks grow downward) and hence must not be used by a Java thread since it may contain stale object references.

// Java threads will process the minimum number of frames needed to continue execution. Concurrent GC threads will take care of the remaining frames, /// ensuring that all thread stacks and other thread roots are eventually processed. 
// Synchronization, utilizing the stack watermark barrier, will  ensure that Java threads do not return into a frame while the GC is processing it.

=== !
The only activities still done in GC safepoints are a subset of root processing and a time-bounded marking termination operation. 

=== !

Project Loom 

It necessary for Project Loom for lazy stack processing 

// The throughput cost of the improved latency should be insignificant.
// Less than one millisecond should be spent inside ZGC safepoints on typical machines.

// JavaThread::wait_for_object_deoptimization
// SafepointMechanism::process(JavaThread *thread, bool allow_suspend)
// (reachability) ( void StackWatermark::start_processing_impl(void* context) (TODO)

=== !

OopMaps

OopMaps contain a list of all registers and stack-slots containing oops (so
they can be updated by GC)

OopMaps also contain a list of derived-pointer base-pointer pairs. 

This oopmap will only be used if we are unwinding the stack

// The functions in this file builds OopMaps after all scheduling is done.
//
// OopMaps contain a list of all registers and stack-slots containing oops (so
// they can be updated by GC).  OopMaps also contain a list of derived-pointer
// base-pointer pairs.  When the base is moved, the derived pointer moves to
// follow it.  Finally, any registers holding callee-save values are also
// recorded.  These might contain oops, but only the caller knows.
//
// BuildOopMaps implements a simple forward reaching-defs solution.  At each
// GC point we'll have the reaching-def Nodes.  If the reaching Nodes are
// typed as pointers (no offset), then they are oops.  Pointers+offsets are
// derived pointers, and bases can be found from them.  Finally, we'll also
// track reaching callee-save values.  Note that a copy of a callee-save value
// "kills" it's source, so that only 1 copy of a callee-save value is alive at
// a time.
//
// We run a simple bitvector liveness pass to help trim out dead oops.  Due to
// irreducible loops, we can have a reaching def of an oop that only reaches
// along one path and no way to know if it's valid or not on the other path.
// The bitvectors are quite dense and the liveness pass is fast.
//
// At GC points, we consult this information to build OopMaps.  All reaching
// defs typed as oops are added to the OopMap.  Only 1 instance of a
// callee-save register can be recorded.  For derived pointers, we'll have to
// find and record the register holding the base.
//
// The reaching def's is a simple 1-pass worklist approach.  I tried a clever
// breadth-first approach but it was worse (showed O(n^2) in the
// pick-next-block code).
//
// The relevant data is kept in a struct of arrays (it could just as well be
// an array of structs, but the struct-of-arrays is generally a little more
// efficient).  The arrays are indexed by register number (including
// stack-slots as registers) and so is bounded by 200 to 300 elements in
// practice.  One array will map to a reaching def Node (or NULL for
// conflict/dead).  The other array will map to a callee-saved register or
// OptoReg::Bad for not-callee-saved.

// Push an abi_reg_args-frame and store all registers which may be live.
// If requested, create an OopMap: Record volatile registers as
// callee-save values in an OopMap so their save locations will be
// propagated to the RegisterMap of the caller frame during
// StackFrameStream construction (needed for deoptimization; see
// compiledVFrame::create_stack_value).
// If return_pc_adjustment != 0 adjust the return pc by return_pc_adjustment.
// Updated return pc is returned in R31 (if not return_pc_is_pre_saved).
